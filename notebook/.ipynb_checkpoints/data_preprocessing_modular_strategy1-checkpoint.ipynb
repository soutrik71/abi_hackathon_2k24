{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0faaa90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d477b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            (function() {\n",
       "                jb_set_cell(\"# Serialize and save the lists to a pickle file\\nwith open(os.path.join(processed_data_folder, \\\"delist_stores_list.pkl\\\"), \\\"wb\\\") as f:\\n    pickle.dump(delist_stores, f)\\n\\nwith open(os.path.join(processed_data_folder, \\\"delist_id_list.pkl\\\"), \\\"wb\\\") as f:\\n    pickle.dump(delist_ids, f)\")\n",
       "            })();\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_black\n",
    "jupyter_black.load(lab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85059acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/abi_hackathon_2k24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    r\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/copilot-model-run/code/Users/Soutrik.Chowdhury/abi_hackathon_2k24\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f480c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "from pandarallel import pandarallel\n",
    "import re\n",
    "from datetime import datetime\n",
    "import gc\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from helpers.compress import reduce_mem_usage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29206564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 14 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True, nb_workers=os.cpu_count() - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1db782f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "processed_data_folder = \"processed_data_S1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1312cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_df = pd.read_csv(f\"{data_folder}/hackathon_training_data_csv_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6882981f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                 0\n",
       "month                0\n",
       "day                  0\n",
       "sales_volume_hl      0\n",
       "ppg_name             0\n",
       "unique_poc_id      130\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df = volume_df.drop([\"Unnamed: 0\"], axis=1)\n",
    "volume_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccff9419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39825098, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe0a89",
   "metadata": {},
   "source": [
    "#### Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "832578bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocessing(df):\n",
    "    # removing nulls\n",
    "    df = df.loc[\n",
    "        (df[\"unique_poc_id\"].notnull()) & (df[\"ppg_name\"].notnull())\n",
    "    ].reset_index(drop=True)\n",
    "    # clean name\n",
    "    df[\"ppg_name_clean\"] = df[\"ppg_name\"].parallel_apply(\n",
    "        lambda x: re.sub(r\"\\s+\", \"_\", x)\n",
    "    )\n",
    "    # poc-Ppg id\n",
    "    df[\"poc_ppg_id\"] = df.parallel_apply(\n",
    "        lambda x: str(x[\"unique_poc_id\"]) + \"__\" + str(x[\"ppg_name_clean\"]), axis=1\n",
    "    )\n",
    "\n",
    "    # date column\n",
    "    df[\"date\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "    df = (\n",
    "        df.groupby([\"poc_ppg_id\", \"date\", \"ppg_name\", \"unique_poc_id\"])\n",
    "        .agg(sales_volume_hl=(\"sales_volume_hl\", \"mean\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71bc5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d7309f7422480ca2875f3a75336b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2844641), Label(value='0 / 2844641…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d643fc037027432dbe16e8a78ccff540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2844641), Label(value='0 / 2844641…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "volume_df = basic_preprocessing(volume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92b878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poc_ppg_id</th>\n",
       "      <th>date</th>\n",
       "      <th>ppg_name</th>\n",
       "      <th>unique_poc_id</th>\n",
       "      <th>sales_volume_hl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAA__AK_AB_CG_T</td>\n",
       "      <td>2019-04-20</td>\n",
       "      <td>AK AB CG T</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.065803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAA__AK_AB_CG_T</td>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>AK AB CG T</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.131605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAA__AK_CW_FM_CG_T</td>\n",
       "      <td>2020-06-13</td>\n",
       "      <td>AK CW FM CG T</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.098704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAA__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>AR EW N DS CG T</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAA__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>AR EW N DS CG T</td>\n",
       "      <td>AAAA</td>\n",
       "      <td>0.164507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              poc_ppg_id       date         ppg_name unique_poc_id  \\\n",
       "0       AAAA__AK_AB_CG_T 2019-04-20       AK AB CG T          AAAA   \n",
       "1       AAAA__AK_AB_CG_T 2019-05-25       AK AB CG T          AAAA   \n",
       "2    AAAA__AK_CW_FM_CG_T 2020-06-13    AK CW FM CG T          AAAA   \n",
       "3  AAAA__AR_EW_N_DS_CG_T 2019-02-11  AR EW N DS CG T          AAAA   \n",
       "4  AAAA__AR_EW_N_DS_CG_T 2019-02-15  AR EW N DS CG T          AAAA   \n",
       "\n",
       "   sales_volume_hl  \n",
       "0         0.065803  \n",
       "1         0.131605  \n",
       "2         0.098704  \n",
       "3         0.000000  \n",
       "4         0.164507  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a07c6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1289.84 Mb (15.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "volume_df = reduce_mem_usage(volume_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9785f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39779240, 5)\n",
      "poc_ppg_id         0\n",
      "date               0\n",
      "ppg_name           0\n",
      "unique_poc_id      0\n",
      "sales_volume_hl    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(volume_df.shape)\n",
    "print(volume_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed86ae",
   "metadata": {},
   "source": [
    "#### start and end dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a2084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_id_df(df, max_gap_month):\n",
    "\n",
    "    # id wise min max dates\n",
    "    id_life_df = df.groupby(\n",
    "        [\"poc_ppg_id\", \"unique_poc_id\", \"ppg_name\"], as_index=False\n",
    "    ).agg(\n",
    "        start_date_vol=(\"date\", \"min\"),\n",
    "        end_date_vol=(\"date\", \"max\"),\n",
    "        unique_selling_days=(\"date\", \"count\"),\n",
    "    )\n",
    "\n",
    "    # life of the id\n",
    "    id_life_df[\"life_from_start_months\"] = (\n",
    "        datetime.now().year - id_life_df[\"start_date_vol\"].dt.year\n",
    "    ) * 12 + (datetime.now().month - id_life_df[\"start_date_vol\"].dt.month)\n",
    "\n",
    "    # last when sold id\n",
    "    id_life_df[\"last_selling_record_months\"] = (\n",
    "        datetime.now().year - id_life_df[\"end_date_vol\"].dt.year\n",
    "    ) * 12 + (datetime.now().month - id_life_df[\"end_date_vol\"].dt.month)\n",
    "\n",
    "    id_life_df[\"inactive_life\"] = round(\n",
    "        id_life_df[\"last_selling_record_months\"] / id_life_df[\"life_from_start_months\"],\n",
    "        2,\n",
    "    )\n",
    "    # store last recorded date\n",
    "    id_life_df[\"poc_last_sell_date\"] = id_life_df.groupby([\"unique_poc_id\"])[\n",
    "        \"end_date_vol\"\n",
    "    ].transform(lambda x: x.max())\n",
    "\n",
    "    # ppg last recorded date\n",
    "    id_life_df[\"ppg_last_sell_date\"] = id_life_df.groupby([\"ppg_name\"])[\n",
    "        \"end_date_vol\"\n",
    "    ].transform(lambda x: x.max())\n",
    "\n",
    "    # store gap from current\n",
    "    id_life_df[\"poc_last_sell_months\"] = (\n",
    "        datetime.now().year - id_life_df[\"poc_last_sell_date\"].dt.year\n",
    "    ) * 12 + (datetime.now().month - id_life_df[\"poc_last_sell_date\"].dt.month)\n",
    "\n",
    "    # ppg gap from current\n",
    "    id_life_df[\"ppg_last_sell_months\"] = (\n",
    "        datetime.now().year - id_life_df[\"poc_last_sell_date\"].dt.year\n",
    "    ) * 12 + (datetime.now().month - id_life_df[\"poc_last_sell_date\"].dt.month)\n",
    "\n",
    "    # Lets first remove those stores which have already been delisted and then remove delisted ids\n",
    "    delist_stores = (\n",
    "        id_life_df.loc[\n",
    "            id_life_df[\"poc_last_sell_months\"] > max_gap_month, \"unique_poc_id\"\n",
    "        ]\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "    # remove ids which has no record for last\n",
    "    delist_ids = (\n",
    "        id_life_df.loc[\n",
    "            (id_life_df[\"last_selling_record_months\"] > max_gap_month),  # delist ids\n",
    "            \"poc_ppg_id\",\n",
    "        ]\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    # donot take the delist stores and delist ids\n",
    "    id_life_df_new = id_life_df.loc[\n",
    "        ~(id_life_df[\"unique_poc_id\"].isin(delist_stores))\n",
    "        & ~(id_life_df[\"poc_ppg_id\"].isin(delist_ids))\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # mapping key for merge\n",
    "    id_life_df_new[\"key\"] = 1\n",
    "\n",
    "    return delist_stores, delist_ids, id_life_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301888f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delist_stores, delist_ids, id_life_df = date_id_df(volume_df, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "691f68f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 49.07 Mb (42.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "id_life_df = reduce_mem_usage(id_life_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1445270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               poc_ppg_id unique_poc_id          ppg_name start_date_vol  \\\n",
      "0   AAAC__AR_EW_N_DS_CG_T          AAAC   AR EW N DS CG T     2019-03-12   \n",
      "1  AAAC__AR_EW_N_DS_ES_AN          AAAC  AR EW N DS ES AN     2019-01-22   \n",
      "2  AAAC__AR_EW_N_DS_FN_DY          AAAC  AR EW N DS FN DY     2019-01-08   \n",
      "3       AAAC__BP_BJ_CG_EH          AAAC       BP BJ CG EH     2019-01-15   \n",
      "4       AAAC__BP_BJ_ES_AN          AAAC       BP BJ ES AN     2019-01-15   \n",
      "\n",
      "  end_date_vol  unique_selling_days  life_from_start_months  \\\n",
      "0   2022-12-20                   74                      64   \n",
      "1   2022-12-27                   84                      66   \n",
      "2   2022-12-02                  102                      66   \n",
      "3   2022-12-20                  108                      66   \n",
      "4   2022-12-20                   98                      66   \n",
      "\n",
      "   last_selling_record_months  inactive_life poc_last_sell_date  \\\n",
      "0                          19       0.300049         2022-12-28   \n",
      "1                          19       0.290039         2022-12-28   \n",
      "2                          19       0.290039         2022-12-28   \n",
      "3                          19       0.290039         2022-12-28   \n",
      "4                          19       0.290039         2022-12-28   \n",
      "\n",
      "  ppg_last_sell_date  poc_last_sell_months  ppg_last_sell_months  key  \n",
      "0         2022-12-31                    19                    19    1  \n",
      "1         2022-12-31                    19                    19    1  \n",
      "2         2022-12-31                    19                    19    1  \n",
      "3         2022-12-31                    19                    19    1  \n",
      "4         2022-12-31                    19                    19    1  \n",
      "(791602, 14)\n",
      "poc_ppg_id                    0\n",
      "unique_poc_id                 0\n",
      "ppg_name                      0\n",
      "start_date_vol                0\n",
      "end_date_vol                  0\n",
      "unique_selling_days           0\n",
      "life_from_start_months        0\n",
      "last_selling_record_months    0\n",
      "inactive_life                 0\n",
      "poc_last_sell_date            0\n",
      "ppg_last_sell_date            0\n",
      "poc_last_sell_months          0\n",
      "ppg_last_sell_months          0\n",
      "key                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(id_life_df.head())\n",
    "print(id_life_df.shape)\n",
    "print(id_life_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b055f3",
   "metadata": {},
   "source": [
    "#### Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb7b55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_df = pd.read_csv(\n",
    "    os.path.join(data_folder, \"South_Africa_Holidays_2019_2022.csv\")\n",
    ")\n",
    "\n",
    "\n",
    "def sin_transformer(period):\n",
    "    return lambda x: np.sin(x / period * 2 * np.pi)\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return lambda x: np.cos(x / period * 2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d817aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calendar_df():\n",
    "    # holidays df\n",
    "    holidays_df[\"Date\"] = pd.to_datetime(holidays_df[\"Date\"])\n",
    "    holidays_df.columns = [col.lower() for col in holidays_df.columns]\n",
    "\n",
    "    # calendar at daily from date1 to date2\n",
    "    calendar_df = pd.DataFrame(\n",
    "        pd.date_range(start=\"2019-01-01\", end=\"2023-12-31\", freq=\"D\"), columns=[\"date\"]\n",
    "    )\n",
    "\n",
    "    calendar_df[\"year\"] = calendar_df[\"date\"].dt.year\n",
    "    calendar_df[\"month\"] = calendar_df[\"date\"].dt.month\n",
    "    calendar_df[\"week\"] = calendar_df[\"date\"].dt.isocalendar().week\n",
    "\n",
    "    # adjusting for week-53\n",
    "    calendar_df[\"adjusted_year\"] = calendar_df.parallel_apply(\n",
    "        lambda x: x[\"year\"] - 1 if x[\"week\"] == 53 and x[\"month\"] == 1 else x[\"year\"],\n",
    "        axis=1,\n",
    "    )\n",
    "    calendar_df[\"adjusted_month\"] = calendar_df.parallel_apply(\n",
    "        lambda x: 12 if x[\"week\"] == 53 and x[\"month\"] == 1 else x[\"month\"], axis=1\n",
    "    )\n",
    "\n",
    "    # features\n",
    "    calendar_df[\"day_of_the_week\"] = calendar_df[\"date\"].dt.dayofweek\n",
    "    # 0-Monday and so on\n",
    "    calendar_df[\"is_weekend\"] = calendar_df[\"date\"].dt.dayofweek // 4\n",
    "    calendar_df[\"is_month_start\"] = calendar_df[\"date\"].dt.is_month_start.astype(int)\n",
    "    calendar_df[\"is_month_end\"] = calendar_df[\"date\"].dt.is_month_end.astype(int)\n",
    "    calendar_df[\"quarter\"] = calendar_df[\"date\"].dt.quarter\n",
    "\n",
    "    calendar_df[\"key\"] = 1  # key for merging with unique combinations of id\n",
    "\n",
    "    # merging the calendar records\n",
    "    calendar_df = pd.merge(\n",
    "        calendar_df, holidays_df[[\"date\", \"holiday\"]], how=\"left\", on=\"date\"\n",
    "    )\n",
    "\n",
    "    # holiday marker\n",
    "    calendar_df[\"holiday\"] = calendar_df[\"holiday\"].parallel_apply(\n",
    "        lambda x: 1 if not pd.isnull(x) else 0.0\n",
    "    )\n",
    "\n",
    "    calendar_df[\"month_sin\"] = calendar_df[\"month\"].apply(sin_transformer(12))\n",
    "    calendar_df[\"month_cos\"] = calendar_df[\"month\"].apply(cos_transformer(12))\n",
    "\n",
    "    calendar_df[\"week_sin\"] = calendar_df[\"week\"].apply(sin_transformer(52))\n",
    "    calendar_df[\"week_cos\"] = calendar_df[\"week\"].apply(cos_transformer(52))\n",
    "\n",
    "    calendar_df[\"quarter_sin\"] = calendar_df[\"quarter\"].apply(sin_transformer(4))\n",
    "    calendar_df[\"quarter_cos\"] = calendar_df[\"quarter\"].apply(cos_transformer(4))\n",
    "\n",
    "    return calendar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d032fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf997582bbfa423eaacd8777cc11e692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=131), Label(value='0 / 131'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed36d752f8345adb9fe1ea7e4f3cc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=131), Label(value='0 / 131'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4ebf5311aa45c3af8c4b11d61e98b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=131), Label(value='0 / 131'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calendar_df = calendar_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "267a15d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1826, 19)\n",
      "date               0\n",
      "year               0\n",
      "month              0\n",
      "week               0\n",
      "adjusted_year      0\n",
      "adjusted_month     0\n",
      "day_of_the_week    0\n",
      "is_weekend         0\n",
      "is_month_start     0\n",
      "is_month_end       0\n",
      "quarter            0\n",
      "key                0\n",
      "holiday            0\n",
      "month_sin          0\n",
      "month_cos          0\n",
      "week_sin           0\n",
      "week_cos           0\n",
      "quarter_sin        0\n",
      "quarter_cos        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>adjusted_year</th>\n",
       "      <th>adjusted_month</th>\n",
       "      <th>day_of_the_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>quarter</th>\n",
       "      <th>key</th>\n",
       "      <th>holiday</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>quarter_sin</th>\n",
       "      <th>quarter_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year  month  week  adjusted_year  adjusted_month  \\\n",
       "0 2019-01-01  2019      1     1           2019               1   \n",
       "1 2019-01-02  2019      1     1           2019               1   \n",
       "2 2019-01-03  2019      1     1           2019               1   \n",
       "3 2019-01-04  2019      1     1           2019               1   \n",
       "4 2019-01-05  2019      1     1           2019               1   \n",
       "\n",
       "   day_of_the_week  is_weekend  is_month_start  is_month_end  quarter  key  \\\n",
       "0                1           0               1             0        1    1   \n",
       "1                2           0               0             0        1    1   \n",
       "2                3           0               0             0        1    1   \n",
       "3                4           1               0             0        1    1   \n",
       "4                5           1               0             0        1    1   \n",
       "\n",
       "   holiday  month_sin  month_cos  week_sin  week_cos  quarter_sin  \\\n",
       "0      1.0        0.5   0.866025  0.120537  0.992709          1.0   \n",
       "1      0.0        0.5   0.866025  0.120537  0.992709          1.0   \n",
       "2      0.0        0.5   0.866025  0.120537  0.992709          1.0   \n",
       "3      0.0        0.5   0.866025  0.120537  0.992709          1.0   \n",
       "4      0.0        0.5   0.866025  0.120537  0.992709          1.0   \n",
       "\n",
       "    quarter_cos  \n",
       "0  6.123234e-17  \n",
       "1  6.123234e-17  \n",
       "2  6.123234e-17  \n",
       "3  6.123234e-17  \n",
       "4  6.123234e-17  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(calendar_df.shape)\n",
    "print(calendar_df.isnull().sum())\n",
    "calendar_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc22bd0",
   "metadata": {},
   "source": [
    "#### Id Time continous flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3086822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 56518.63 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "poc_ppg_cont_df = pd.merge(\n",
    "    id_life_df[[\"poc_ppg_id\", \"start_date_vol\", \"end_date_vol\", \"key\"]],\n",
    "    calendar_df[[\"date\", \"key\"]],\n",
    "    on=\"key\",\n",
    ")\n",
    "\n",
    "poc_ppg_cont_df = reduce_mem_usage(poc_ppg_cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f929d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the actual starting date for each combinations\n",
    "poc_ppg_cont_df = poc_ppg_cont_df.loc[\n",
    "    poc_ppg_cont_df[\"date\"] >= poc_ppg_cont_df[\"start_date_vol\"]\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f24578c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in right order\n",
    "poc_ppg_cont_df = poc_ppg_cont_df.sort_values(\n",
    "    [\"poc_ppg_id\", \"date\"], ascending=[True, True]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89a4df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1019803948, 5)\n",
      "poc_ppg_id                object\n",
      "start_date_vol    datetime64[ns]\n",
      "end_date_vol      datetime64[ns]\n",
      "key                         int8\n",
      "date              datetime64[ns]\n",
      "dtype: object\n",
      "poc_ppg_id        0\n",
      "start_date_vol    0\n",
      "end_date_vol      0\n",
      "key               0\n",
      "date              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(poc_ppg_cont_df.shape)\n",
    "print(poc_ppg_cont_df.dtypes)\n",
    "print(poc_ppg_cont_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f58283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poc_ppg_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAC__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-03-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAC__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAC__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-03-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAC__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAC__AR_EW_N_DS_CG_T</td>\n",
       "      <td>2019-03-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              poc_ppg_id       date\n",
       "0  AAAC__AR_EW_N_DS_CG_T 2019-03-12\n",
       "1  AAAC__AR_EW_N_DS_CG_T 2019-03-13\n",
       "2  AAAC__AR_EW_N_DS_CG_T 2019-03-14\n",
       "3  AAAC__AR_EW_N_DS_CG_T 2019-03-15\n",
       "4  AAAC__AR_EW_N_DS_CG_T 2019-03-16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poc_ppg_cont_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c94b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "poc_ppg_cont_df = poc_ppg_cont_df.drop(\n",
    "    [\"start_date_vol\", \"end_date_vol\", \"key\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3185796",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(), processed_data_folder), exist_ok=True)\n",
    "poc_ppg_cont_df.to_pickle(\n",
    "    os.path.join(os.getcwd(), processed_data_folder, \"poc_ppg_daily_continous.pkl\")\n",
    ")\n",
    "calendar_df.to_pickle(\n",
    "    os.path.join(os.getcwd(), processed_data_folder, \"calendar_daily.pkl\")\n",
    ")\n",
    "volume_df.to_pickle(\n",
    "    os.path.join(os.getcwd(), processed_data_folder, \"volume_daily_clean.pkl\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65a74932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the lists to a pickle file\n",
    "with open(os.path.join(processed_data_folder, \"delist_stores_list.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(delist_stores, f)\n",
    "\n",
    "with open(os.path.join(processed_data_folder, \"delist_id_list.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(delist_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e740db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
